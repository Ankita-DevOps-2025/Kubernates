# Multi container pods
In this lecture, we will discuss multi-container pods in Kubernetes.

Modern application design often follows the principle of decoupling large monolithic applications into smaller, independent components, known as microservices. This approach allows each service to be developed, deployed, and scaled independently, which provides flexibility and efficiency compared to modifying and deploying an entire application as a single unit.

However, there are scenarios where two services need to run together. For example, imagine you have a web server that must always run alongside a main application. You do not want to merge their codebases because they serve different purposes and may be developed by separate teams. At the same time, you need them to run as a pair—scaling up and down together, and always remaining tightly coupled in execution.

This is where multi-container pods come in. In Kubernetes, a pod can contain more than one container. These containers share the same lifecycle—they are created, scheduled, and destroyed together. They also share the same network space, which means they can communicate with each other using localhost. Additionally, they share the same storage volumes, enabling easy data exchange without needing extra services or volume mounts across pods.

To define a multi-container pod, you simply add multiple containers in the pod’s definition file. The containers field inside the spec section is defined as an array, which allows Kubernetes to manage more than one container within the same pod. For example, you might define one container called web-app and another called main-app, both part of a single pod.

This is a simple case of combining two services within a pod. In real-world scenarios, multi-container pods are often used for patterns such as sidecar containers (for logging or proxying), adapter containers (for transforming data), or ambassador containers (for connecting external services). We will explore these advanced use cases later in the course.

# Multi-container Pods Design Patterns
In this lecture, we will explore the different design patterns for multi-container pods in Kubernetes.

The simplest pattern is known as the co-located containers pattern. This is the original and most straightforward form of multi-container pods. Here, two or more containers are simply defined within the same pod. All of them are created together, and all continue to run throughout the lifecycle of the pod. This pattern is commonly used when two services depend on each other and must always run side by side. A good example would be a main application paired with a helper service that both need to remain active at the same time.

The second pattern is called the init container. This type of container is designed to run before the main application starts. Init containers are particularly useful when certain initialization steps must be completed before the application can begin. For example, an init container might wait for a database to be ready before starting the application. Unlike regular containers, init containers run their task once and then terminate. Only after all init containers complete successfully does the main application container start. Kubernetes also allows you to define multiple init containers, which will run sequentially in the order they are defined—one after another—ensuring tasks such as API checks, configuration downloads, or environment preparation are carried out in the right sequence before the main workload begins.

The third design pattern is the sidecar container. A sidecar container resembles an init container in the sense that it can be set up to start before the main application. However, unlike init containers, sidecars do not exit once they finish their initial task. Instead, they continue to run alongside the main application throughout the entire lifecycle of the pod. This is useful in cases where continuous background processing is required. A common use case is log collection: you might deploy a sidecar container that ships logs to an external system while the main application runs. By starting before the main application, the sidecar ensures that even the application’s startup logs are captured, and by ending only after the main container stops, it ensures termination logs are collected as well.

A practical example of this pattern can be seen in the Elastic Stack. Suppose you run an application alongside a sidecar container such as Filebeat, which is responsible for shipping logs to Elasticsearch. Filebeat starts before the main app so it can capture initialization logs, runs continuously to process runtime logs, and finally captures termination logs if the application crashes or stops. This sidecar pattern makes it possible to enhance applications with capabilities like monitoring, logging, or proxying without altering the application code itself.

To summarize:
* Co-located containers run together without startup order guarantees.
* Init containers run first, complete their work, and then exit before the main app begins.
* Sidecar containers start before or alongside the main application and continue running until the pod terminates.

These three multi-container pod patterns give Kubernetes the flexibility to handle a wide range of real-world application scenarios.

# Init Containers
In a multi-container pod, each container is expected to run a process that stays alive as long as the POD's lifecycle. For example in the multi-container pod that we talked about earlier that has a web application and logging agent, both the containers are expected to stay alive at all times. The process running in the log agent container is expected to stay alive as long as the web application is running. If any of them fails, the POD restarts.

But at times you may want to run a process that runs to completion in a container. For example a process that pulls a code or binary from a repository that will be used by the main web application. That is a task that will be run only one time when the pod is first created. Or a process that waits for an external service or database to be up before the actual application starts. That's where initContainers comes in.

An initContainer is configured in a pod like all other containers, except that it is specified inside a initContainers section, like this:

apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: ['sh', '-c', 'echo The app is running! && sleep 3600']
  initContainers:
  - name: init-myservice
    image: busybox
    command: ['sh', '-c', 'git clone <some-repository-that-will-be-used-by-application> ;']

When a POD is first created the initContainer is run, and the process in the initContainer must run to a completion before the real container hosting the application starts.
You can configure multiple such initContainers as well, like how we did for multi-pod containers. In that case each init container is run one at a time in sequential order.

If any of the initContainers fail to complete, Kubernetes restarts the Pod repeatedly until the Init Container succeeds.
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: ['sh', '-c', 'echo The app is running! && sleep 3600']
  initContainers:
  - name: init-myservice
    image: busybox:1.28
    command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']
  - name: init-mydb
    image: busybox:1.28
    command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;']

Read more about initContainers here. And try out the upcoming practice test.
https://kubernetes.io/docs/concepts/workloads/pods/init-containers/


